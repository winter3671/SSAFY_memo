## AI & 기계학습 기초 1

### AI, ML, DL의 정의
- AI(Artificial Intelligence)
  - 주어진 환경/데이터를 인지, 학습, 추론을 통해 목표 달성을 하도록 예측, 행동 선택, 계획하는 시스템
- ML(Machine Learning)
  - AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론
  - 예: 언어 모델, 이미지 분류 모델, 추천 시스템
- DL(Deep Learning)
  - ML 범주 내에서 신경망(Neural Network) 함수를 사용한 학습 방법론
- AI - ML(ML이 아닌 AI 시스템)의 예
  - 규칙 기반 시스템
  - 휴리스틱 기반(최적화) 알고리즘

### 데이터와 학습의 이해
#### 데이터 구성요소
- 데이터가 왜 중요한가?
  - 머신러닝은 규칙을 직접 코딩하지 않고, 데이터에서 규칙을 학습
  - 데이터(Feature, Label)의 분포와 관계가 머신러닝의 학습 결과를 결정
- Feature(피처, 특성)
  - 모델이 예측에 사용하는 입력정보
  - 예측, 판단의 근거/단서
- Label(라벨, 목표값)
  - 모델이 예측하려는 정답
  - 학습의 목표값

#### ML 실생활 예시
- 예시 1 - 유튜브 추천
  - Feature: 각 영상들의 정보(장르, 크리에이터, 조회수, 좋아요 수 등), 사용자 정보(시청 이력, 구독 채널 등)
  - Label: 영상에 대한 사용자 피드백(시청 여부, 좋아요 클릭 여부)
- 예시 2 - 스팸메일 분류
  - Feature: 메일 제목, 발신자, 단어 빈도
  - Label: 스팸/정상

### 단일 피쳐 기반 학습
#### 1D 피쳐 기반 학습
- 1D 피쳐 기반 학습(단일 피쳐 학습)이란?
  - 1D = 1차원
  - Feature가 하나일 때 머신러닝이 학습하는 가장 단순한 형태
- ![단일 피쳐 학습](수업자료/3-1%20학력과%20수입%20데이터.png)
- Income<sub>i</sub> = f<sup>*</sup>(Years of Education<sub>i</sub>) + ε<sub>i</sub>  
  - f<sup>*</sup>: 미지의 참 함수  
  - ε<sub>i</sub>: 측정 오차
  - 데이터셋 D: 30명의 **Years of Education (피처)** 와 **Income (라벨)** 쌍  
  - D = { (Years of Education<sub>i</sub>, Income<sub>i</sub>) }<sub>i=1</sub><sup>30</sup>
    - 미지의 함수 f<sup>*</sup>
      - Feature와 Label 사이의 실제 평균 관계  
      - 하지만 직접 관찰할 수 없음  
      - 오차가 포함된 데이터(점)만 관측 가능
    - 측정 오차 ε
      - 데이터에는 주로 **측정 오차**가 섞여 있음  
      - 원인: 측정 기기의 한계, 환경적 요인 등  
      - 따라서 데이터 = 참 함수 + 오차 (f<sup>*</sup> + ε)
- 피쳐와 라벨의 관계를 잘 나타내는 함수 f는?
  - 데이터를 설명하는 여러 함수 후보가 존재
  - 어떤 함수가 가장 잘 맞는지 학습해야 함

#### 모델과 가설 공간
- 학습(Learning)
  - "입력(Feature) -> 출력(Label)" 관계를 찾는 과정
  - 평균 관계를 하나의 함수로 표현함
  - 하지만 관계를 표현할 수 있는 함수는 무수히 많음
- 가설 공간(Hypothesis Space)
  - 관계를 표현할 수 있는 모든 후보 함수들의 모음
  - 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합 𝓕
- 모델(Model)
  - 가설공간 𝓕에 속한 특정 함수 f
- ![가설공간과 모델](수업자료/3-1%20학력과%20수입%20데이터%20-%20가설공간과%20모델.png)
- ![선형함수와 비선형함수](수업자료/3-1%20선형함수와%20비선형함수.png)

#### 학습이란
- 학습
  - 주어진 데이터와 성능척도를 바탕으로 가설공간 𝓕의 후보들 중 최적의 모델을 선택하는 과정
  - 데이터 D → 가설공간 𝓕 → 선택된 모델 f
- ![학습](수업자료/3-3%20학습.png)

### 복수 피쳐 기반 학습
#### 2D 피쳐 기반 학습
- Income = f<sup>*</sup>(Years of Education, Seniority) + ε
  - f<sup>*</sup>: 미지의 참 함수 (입력과 출력을 이어주는 숨겨진 진짜 함수)
  - 파란색 Surface(=미지의 참 함수 f)는 관측 불가능
  - 빨간색 점들(=데이터)만 관측 가능함
  - 학습 전: 어떤 가설공간 𝓕을 사용할까?
  - 학습 후: 데이터를 활용하여 어떤 모델 f을 선택해야 할까?
- ![2D 피쳐 기반 학습](수업자료/4-1%202D%20피쳐%20기반%20학습.png)
- ![2D 피쳐 기반 학습](수업자료/4-1%20선형함수와%20비선형함수.png)

#### 일반적 용어 정리 및 모델 가정
- Income = f<sup>*</sup>(Years of Education, Seniority, ...) + ε → Y = f<sup>*</sup>(X) + ε
  - Income: 우리가 예측하려는 라벨(반응/목표) 변수 → Y로 표기
  - Years of Education: 첫번째 피처(입력/예측) 변수 → X<sub>1</sub>로 표기
  - Seniority: 두번째 피처(입력/예측) 변수 → X<sub>2</sub>로 표기
  - 다른 i번째 피처가 있다면 역시 X<sub>i</sub>로 표기
  - 일반적인 p차원 피처(총 p개의 피처) 벡터: X = [X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>p</sub>]<sup>T</sup> ∈ ℝ<sup>p</sup>
  - 모델(함수형) : f<sup>*</sup>: ℝ<sup>p</sup> → ℝ, Y = f<sup>*</sup>(X) + ε
  - 측정오차 ε : ε는 피처 X와 독립 및 E[ε] = 0로 가정함

#### 왜 f(·)를 학습하는가?
- 예측
  - 잘 학습된 f가 있으면, 새로운 입력 X = x에서 반응/목표 Y를 예측할 수 있음
- 중요 특성 파악
  - 피처들 X = (X₁, X₂, ..., Xₚ)의 어떤 특성이 Y를 설명하는데 중요하고, 어떤 것은 덜 중요(무관)한지 알 수 있음
    - 예: 근속연수(Seniority), 교육기간(Years of Education)은 소득(Income)에 큰 영향을 줄 수 있지만, 혼인 여부(Marital Status)는 영향이 거의 없을 것임
- 해석 가능성
  - f의 복잡도에 따라 각 구성요소 Xⱼ가 Y에 어떻게 영향을 미치는지(증가/감소 방향, 민감도 등) 이해할 수 있음

### 요악 및 정리
- AI와 ML
  - AI: 주어진 환경/데이터를 인지·학습·추론하여 목표 달성을 위한 예측·행동 선택·계획을 수행하는 시스템
  - ML: AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 방법론
- 데이터의 구성 요소
  - Feature: 모델 입력 정보, 예측·판단의 근거
  - Label: 모델이 예측하려는 정답, 학습의 목표
- 1D 피처 기반 학습
  - Feature가 하나일 때(1차원) 수행되는 단순한 학습 형태
  - Feature와 Label 사이의 관계를 함수 f로 표현하되, 실제 데이터에는 측정오차 (ε)가 포함됨
- 모델과 가설 공간
  - 가설 공간(𝓕): Feature와 Label 관계를 표현할 수 있는 함수들의 집합
  - 모델: 가설 공간 내 특정 함수 f
- 학습
  - 데이터와 성능 척도를 바탕으로 가설 공간 𝓕 내 후보 중 최적의 모델을 선택하는 과정
- 모델 학습의 필요성
  - 예측: 새로운 입력값에 대해 Label을 추론
  - 중요 특성 파악: 어떤 Feature가 결과에 중요한지 확인
  - 해석 가능성: 각 Feature가 결과에 어떤 영향을 미치는지 이해

## AI & 기계학습 기초 2
### 지도학습의 개념
#### 지도학습(supervised learning)이란?
- 데이터
  - 입력(특성)과 정답(라벨)이 쌍으로 있는 데이터
- 목표
  - 새 입력이 들어오면 정답을 잘 맞추는 규칙을 학습
- 지도학습의 종류
  - 회귀: 예측값이 숫자(가격, 점수, 온도)
  - 분류: 예측값이 범주(스팸/정상, 질병 유/무)
- ![지도학습](수업자료2/1-1%20지도학습.png)

#### 지도학습 용어
- 특성(Feature, x)
  - 예측에 쓰는 설명 변수
    - 예: 집값 예측 {지역, 평수, 방수, 연식}, 이메일 스팸 필터링 {제목, 내용 텍스트, 송신인}
- 라벨(Label, y)
  - 맞춰야 하는 정답
    - 예: 집값, 스팸/정상이메일
- 예측값(ŷ)
  - 모델이 내놓은 결과(숫자 또는 범주)
- 오류(Error)
  - 예측값(ŷ)과 라벨(y)의 차이: ŷ - y
- ![지도학습 용어](수업자료2/1-2%20집값%20예측.png)

### 회귀(Regression)
#### 회귀(Regression) 문제
- 입력으로부터 숫자를 얼마나 정확히 예측할까?
  - Feature: 면적·방수·연식 → Label: 집값(원 단위)
  - Feature: 매체별 광고비(TV/라디오/온라인) → Label: 매출액
- 라벨 및 예측 모델의 출력
  - 연속적인 수치
- ![회귀](수업자료2/2-1%20회귀.png)

#### 회귀 오류: 평균제곱오차(MSE)
- 평균제곱오차(Mean Squared Error)
  - 각 데이터에서 정답(yᵢ)과 예측(ŷᵢ)의 평균 제곱 차이값
  - MSE = (1/n) ∑ (yᵢ - ŷᵢ)²
- 해석
  - 큰 오류를 더 크게 벌(penalty)주므로, 전체 오류 수준을 한눈에 봄
- 참고
  - 데이터와 같은 단위를 쓰고 싶으면 RMSE(MSE의 제곱근)도 사용
    - R은 root를 의미
  - RMSE = √MSE = √[(1/n) ∑ (yᵢ - ŷᵢ)²]

#### 회귀 설명력: R² (결정계수)
- 결정계수
  - 라벨의 분산 중에서 특성으로 설명되는 비율
  - "평균만 쓰는 단순한 예측"보다 얼마나 더 잘 맞추는지를 0~1 사이로 나타낸 값
    - R² = 1 - [ Σ(yᵢ - ŷᵢ)² / Σ(yᵢ - ȳ)² ]
    - ȳ = yᵢ들의 평균값
- 해석
  - 1에 가까울수록 설명력이 높고, 낮을수록 설명력이 낮음
- 질문
  - R²가 음수가 나올 수 있을까?
    - 나올 수 있음. 예측값(ŷᵢ)들이 평균값 ȳ보다도 못하다면…

### 분류(Classfication)
#### 분류(Classfication) 문제
- 입력으로부터 범주는 얼마나 정확히 가려낼까?
  - Feature: 메일 내용·보낸이 이메일주소 → Label: 스팸/정상
  - Feature: 종양 반경, 면적 → Label: 악성/양성
- 라벨
  - 범주 라벨(이진/다중)
- ![분류](수업자료2/3-1%20분류.png)

#### 분류 정확도(Accuracy)
- 정확도
  - 전체 중 맞춘 비율
  - Accuracy = (1/n) ∑ 𝕀(yᵢ = ŷᵢ)
    - 𝕀: 지시(indicator) 함수
    - 𝕀(A) = 1 if A true
- 정확도만 보면 발생하는 문제
  - 불균형 데이터(양성 1%, 음성 99%)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있음
- 결론
  - 정확도만 보지 말고 다른 지표도 함께 봐야 안전

#### 혼동행렬(Confusion Matrix)
- 혼동행렬
  - 예측과 실제 값 사이의 관계를 행렬 형태로 표현
  - TP: 실제 양성, 예측도 양성
  - TN: 실제 음성, 예측도 음성
  - FP: 실제는 음성인데 양성이라 함(오탐)
  - FN: 실제는 양성인데 음성이라 함(누락)
- 정밀도(Precision)
  - "양성이라 판정한 것 중" 진짜 양성의 비율 = TP/(TP+FP)
- 재현율(Sensitivity or Recall)
  - "진짜 양성 가운데" 잡아낸 예측 양성 비율 = TP/(TP+FN)
- F1-score
  - 정밀도와 재현율의 조화평균
  - F1 = 2 × (정밀도 × 재현율) / (정밀도 + 재현율)
- ![혿동행렬](수업자료2/3-3%20혼동행렬.png)

### 학습의 목적
#### 학습의 목적
- 학습의 목적은 테스트 예측(일반화)
  - 학습 모델의 성능 평가는 모델이 처음 보는(학습에 사용되지 않은) 데이터로 평가
    - 일반화(generalization) 오류의 최소화 지향
- 훈련 데이터에서 성능이 아무리 좋아도, 새로운 데이터에서 성능이 떨어지면 실전엔 사용할 수 없음
- 다음 차시(3차시)에서 일반화 성능을 추정(검증/교차검증)하는 방법을 배울 예정

#### 오버피팅(overfitting)이란?
- 오버피팅(overfitting)
  - 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 (초록색 함수) 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상
  - 현상: 훈련 오류 급격히 낮음, 테스트 오류 높음/요동
- 오버피팅이 왜 안 좋은가?
  - 표본(sample) 의존·불안정: 훈련 데이터는 모집단의 일부 표본이라 우연한 잡음이 섞임. 이것에만 과하게 맞추어 학습하면 샘플 몇 개만 바뀌어도 예측이 크게 흔들림(분산↑).
  - 일반화 실패: 보지 못한 데이터(테스트) 오류가 커짐, 모(population)집단 성능과 격차가 벌어짐.
- ![오버피팅](수업자료2/4-1%20오버피팅.png)

#### 오버피팅에 대한 오해
- 오버피팅 ≠ 분포 변화(distribution shift)로 인한 에러 증가
  - 분포 변화로 인한 오류: 훈련 데이터 분포와 테스트 분포가 다름으로 (환경·계절·센서 변경 등) 성능이 떨어지는 현상
  - 분포 변화로 인한 에러 증가는 모델이 과적합하지 않아도 발생 가능

#### 오버피팅 vs 언더피팅
- 오버피팅 vs 언더피팅 (균형 잡기)
  - 오버피팅: 모델이 너무 복잡 → 잡음까지 학습(테스트 성능 나쁨)
  - 언더피팅: 모델이 단순하거나 학습이 완료되지 않음 → 중요한 패턴을 놓침(오류 큼) 
- 해결 실마리
  - 더 많은 데이터, 테스트 데이터를 활용한 모델 선정. 교차 검증
- ![오버피팅 vs 언더피팅](수업자료2/4-2%20오버피팅%20vs%20언더피팅.png)

### 요약 및 정리
- 지도학습(Supervised Learning)
  - 입력(Feature)과 정답(Label)이 쌍으로 있는 데이터로 학습
  - 새로운 입력에 대해 정답을 잘 예측하는 규칙을 찾는 과정
  - 종류
    - 회귀(Regression): 연속적인 값 예측 (집값, 점수, 매출액)
    - 분류(Classification): 범주 예측 (스팸/정상, 질병 유무)
- 회귀 평가지표
  - MSE(평균제곱오차): 큰 오류를 더 크게 반영해 전체 오류 수준을 파악
  - R²(결정계수): 모델이 데이터를 얼마나 설명하는지 (0~1 사이, 높을수록 설명력 큼)
- 분류 평가지표
  - 정확도(Accuracy): 전체 중 맞춘 비율 (불균형 데이터에서 한계 존재)
  - 혼동행렬(Confusion Matrix): 예측 vs 실제를 행렬로 표현
- 학습의 목적
  - 일반화(Generalization): 처음 보는 데이터에서도 잘 작동해야 함
  - 훈련 데이터 성능만 좋고 실제 성능이 낮으면 활용 불가
- 오버피팅(Overfitting)
  - 훈련 데이터의 잡음까지 학습 → 훈련 성능↑, 테스트 성능↓
  - 특징: 훈련 오류 작음, 테스트 오류 큼
- 언더피팅(Underfitting)
  - 모델이 너무 단순하거나 학습이 부족 → 중요한 패턴을 놓침
  - 특징: 훈련/테스트 모두 오류 큼
- 균형 잡기 (Overfitting vs Underfitting)
  - 오버피팅: 모델이 너무 복잡 → 과적합
  - 언더피팅: 모델이 너무 단순 → 과소적합
  - 해결 방법: 더 많은 데이터 확보, 테스트 데이터를 활용한 모델 선정, 교차 검증

## AI & 기계학습 기초 3
### 테스트 성능 평가
- 훈련 오류 vs 테스트 오류
  - 훈련 오류: 모델을 학습시킨 같은 데이터에 다시 적용해 계산한 오류
  - 테스트 오류: 학습에 쓰지 않은 새 관측치에 대해 모델을 적용했을 때의 평균 예측오류
  - 보통 훈련 오류는 테스트 오류와 다르며, 특히 훈련 오류는 테스트 오류를 (심하게) 과소평가하는 경우가 많음
    - 예: 암기 vs 응용 시험
- ![훈련오류와 테스트오류](수업자료3/1-1%20훈련오류와%20테스트오류.png)
  - 파란색 선: 훈련 오류
  - 빨간색 선: 테스트 오류
  - 훈련 오류는 계속 ↓, 테스트 오류는 U자형
  - 목적: 테스트 오류의 U자형의 바닥이 되도록 하는 적절한 모델 찾기
- ![언더피팅 오버피팅 곡선](수업자료3/1-2%20언더피팅&오버피팅%20곡선.png)
- 테스트 예측오류 계산
  - 이상적 케이스: 충분히 큰 별도 테스트 데이터셋 → 현실에선 구하기 어려움
  - 현실에서는 테스트만을 위한 데이터를 갖기에 데이터 자체가 부족할 수 있음
- 대안: 재표본화(resampling)를 통한 테스트 오류 추정
  - 데이터를 나눠 여러 번 "훈련→평가"를 반복해 테스트 오류를 가늠
  - 방법: 검증셋(hold-out), K겹 교차검증(K-fold Cross-Validation)
  - 장점: 별도의 테스트 데이터 없이 데이터를 더 효율적으로 사용하여 일반화 오차 추정

### 검증셋(Validation Set) 접근
#### 검증셋(Validation Set) 방법
- 검증셋(홀드아웃) 방법
  - 가용 샘플들을 무작위로 훈련셋과 `검증셋(hold-out)`으로 분할
  - 훈련셋으로 모델 적합, 검증셋으로 예측 후 검증 오류를 계산.
  - 검증 오류는 보통 정량 반응은 MSE, 범주 반응은 오분류율(또는 F1-score)을 측정한다.

#### 검증셋 절차
- 검증 절차
  - 데이터 순서 무작위 셔플링 후 두 부분으로 분할: 왼쪽(파랑)=훈련셋, 오른쪽(주황)=검증셋
  - 학습은 훈련셋에서, 성능평가는 검증셋에서 수행
- ![검증 절차](수업자료3/2-2%20검증%20절차.png)

#### 검증셋 방법 예시
- 예시: 자동차 데이터
  - 목표: `선형`(1차)모델부터 `고차항`(다항식) 모델 비교
  - 392개 데이터를 무작위로 196개 훈련셋/196개 검증셋으로 분할 (일반적으로 반으로 나눌 필요는 없음)
  - 좌측 패널: 단 한 번 분할 시의 MSE 곡선
  - 우측 패널: 여러 번 (셔플 후) 다른 분할의 MSE 곡선들
- ![자동차 데이터](수업자료3/2-3%20자동차%20데이터.png)

#### 검증셋 접근의 한계
- `예시에서 보이는 검증셋 방법의 단점이 무엇일까?`
  - 어떤 표본이 훈련/검증에 들어가느냐에 따라 검증 기반 테스트 오류 추정치가 매우 가변적
  - 검증 접근에서는 훈련셋(=전체의 일부)만으로 모델을 적합하므로, 전체 데이터로 학습했을 때보다 성능이 낮게 추정(즉, 테스트 오류를 과대 추정)될 수 있음
- 왜 전체 데이터로 학습한 모델의 `테스트 오류를 과대 추정하는 경향`이 있을까?
  - 학습에 데이터를 부분만 사용하기 때문

### K-겹 교차검증(K-fold Cross-Validation)
#### K-겹 교차검증
- K-겹 교차검증(K-fold Cross-Validation)
  - 테스트 오류 추정의 표준적 접근
  - 추정치는 모델 선택과 최종 모델의 테스트 오류 규모 파악에 활용
  - 데이터 전체를 크기 동일한 K개 폴드로 무작위 분할
    - → 폴드 k∈{1,2,···,K}를 검증, 나머지 K-1개를 훈련에 사용
  - k=1,···,K에 대해 반복 후, 평균 오류로 테스트 오류를 추정
- K-겹 교차검증 단계
  - 데이터를 먼저 셔플링한 뒤, 총 n개의 데이터를 겹치지 않는 K개 그룹으로 분할
  - 각 그룹이 번갈아 검증셋(주황), 나머지는 훈련셋(파랑)
  - K개의 MSE를 평균해 테스트 오류를 추정
- ![K겹 교차검증](수업자료3/3-1%20K겹%20교차검증.png)

#### K-겹 교차검증 오류 계산
- K-겹 교차검증 오류 계산
  - 폴드 집합 C₁, ···, Cₖ, 각 폴드 크기 nₖ
    - CV(K) = ∑ (nₖ/n) * MSEₖ
  - 여기서, MSEₖ = (1/nₖ) ∑ (yᵢ - ŷᵢ)² (k-폴드를 검증셋으로 두고 나머지로 적합한 예측 ŷᵢ)
  - K = n이면 Leave-One-Out 교차검증(LOOCV)
- Leave-One-Out 교차검증에서 검증셋 크기는?

#### Leave-One-Out 교차검증
- Leave-One-Out 교차검증
  - 훈련셋(파랑): 관측치 하나만 제외한 나머지 전부
  - 검증셋(주황): 제외한 1개 관측치
  - 이 과정을 n번 반복해 나온 n개의 MSE 평균으로 테스트 오류를 추정
- ![Leave-One-Out](수업자료3/3-2%20Leave-One-Out.png)

#### K-겹 교차검증 비교
- Leave-One-Out 교차검증 vs 10-겹 교차검증
  - 자동차 데이터에서 LOOCV와 10-겹 CV 결과 비교(다항 차수에 따른 MSE 곡선)
  - 두 방법의 경향과 최적 차수가 비슷
- ![LOOCV vs 10-Fold CV](수업자료3/3-3%20LOOCV%20vs%2010-Fold%20CV.png)
- 시뮬레이션: 참/추정 테스트 MSE
  - 파랑: 참(test) MSE, 검은 점선: LOOCV 추정, 주황: 10-겹 CV 추정
  - 10-겹 CV 추정: 테스트 성능에 추정의 좋은 대안
- ![참/추정 테스트 MSE](수업자료3/3-4%20참,%20추정%20테스트%20MSE.png)

### 요약 및 정리
- 검증(Validation)
  - 데이터를 훈련셋/검증셋으로 분리
  - 훈련셋으로 모델 적합, 검증셋으로 성능 측정
  - Hold-out, K겹 교차검증(Cross-Validation) 활용
- K겹 교차검증
  - 데이터를 K개로 나눠 반복적으로 학습·평가
  - 모든 데이터를 검증에 사용해 일반화 성능을 더 정확히 추정
  - K = n: LOOCV (Leave-One-Out Cross Validation)
- 테스트 성능 평가
  - 훈련 오류: 학습에 사용된 데이터에서의 오류
  - 테스트 오류: 새 데이터에서의 오류 → 일반화 성능 평가 기준
  - 목표: 테스트 오류가 최소가 되는 모델 선택
- 오버피팅 vs 언더피팅
  - 오버피팅: 모델이 지나치게 복잡 → 훈련 성능↑, 테스트 성능↓
  - 언더피팅: 모델이 지나치게 단순 → 중요한 패턴을 놓쳐 오류 큼

## AI & 기계학습 기초 4
### 비지도학습
- 비지도학습이란?
  - 정의: 레이블(정답) 없이 데이터의 구조·패턴·집단(잠재 서브그룹)을 찾아내는 학습
  - 대표 과제: 군집화(clustering), 차원축소(PCA 등), 밀도추정/이상치 탐지
  - 출력: “정답 예측”이 아니라 구조/요약/표현(embedding)
- 핵심 질문
  - 무엇을 비슷함/다름으로 볼 것인가(거리·유사도 선택)
  - 전처리(스케일 표준화 등)를 어떻게 할 것인가
  - 출력: “정답 예측”이 아니라 구조/요약/표현(embedding)
- 비지도 vs 지도학습
  - 지도학습: 입력+라벨로 예측 모델 학습
    - 예: 가격 예측, 악성 종양 예측
  - 비지도학습: 입력만으로 구조 학습
    - 예: 고객 세그먼트
  - 비지도학습 예
    - 클러스터링: 서로 비슷한 데이터끼리 묶어 동질 그룹 만들기
- ![지도학습 vs 비지도학습](수업자료4/1-1%20지도학습%20vs%20비지도학습.png)

### 클러스터링(Clustering)
- 클러스터링(Clustering)이란?
  - 클러스터링: 데이터 안에서 하위 집단(클러스터)을 찾는 기법들의 총칭
  - 목표: 집단 내부는 서로 유사, 집단 간은 상이하도록 데이터를 분할
  - 유사/상이 정도는 도메인 맥락에 따라 정의가 달라질 수 있음
  - 문제·데이터 특성에 의존
- ![비지도학습](수업자료4/2-1%20비지도학습.png)
- 예시: 마케팅 세그멘테이션
  - 다수의 지표(가구 소득, 직업, 도심 거리 등)를 가진 많은 사람들에 대해 특정 광고/상품에 더 반응할 하위집단을 식별하고자 함.
  - 시장 세분화 작업 자체가 클러스터링에 해당
- ![마케팅 세그먼테이션](수업자료4/2-2%20마케팅%20세그먼테이션.png)
- 두 가지 대표 클러스터링 기법
  - K-평균(K-means): K(클러스터 수)를 미리 정해 분할
  - 계층적 군집(Hierarchical): K를 사전에 고정하지 않음
- ![K-means와 Hierarchical](수업자료4/2-3%20K-means와%20Hierarchical.png)

### K-means 클러스터링
#### K-means 클러스터링
- K-means 클러스터링 결과 예시
  - 패널: K=2, 3, 4에서 각 K-means 결과(점 색상=할당된 클러스터)
  - 클러스터 결과에서 특정 색상은 의미가 없고, 점들이 다른 색이라는 것은 서로 다른 클러스터에 속해있다는 의미
- ![다른 K값에 대한 K-Means 결과](수업자료4/3-1%20다른%20K값에%20대한%20K-means%20결과.png)
- K-means의 표기(군집 집합)
  - 관측치 인덱스 집합을 C₁, ..., Cₖ 라 하면:
  - C₁ ∪ ··· ∪ Cₖ = {1, ..., n} (각 관측치는 적어도 하나의 군집에 속함)
  - 모든 다른 클러스터 k ≠ k'에 대해, Cₖ ∩ Cₖ' = ∅ (겹치지 않음)
  - i번째가 k번째 군집이면 i ∈ Cₖ (비중첩 분할)
- K-means의 핵심 아이디어
  - 좋은 군집화= `클러스터 내부 변동(Within-Cluster Variation)`이 작은 분할
  - 목표: `클러스터 내부 변동의 합`이 `최소`가 되도록 분할을 찾는다
  - 모든 클러스터의 내부 흩어짐 총합이 가장 작은 분할

#### K-means 클러스터링 알고리즘
- K-means 알고리즘
  - 초기화: 관측치들에 무작위로 1···K 클러스터를 임시 부여
  - 반복(할당이 더 이상 바뀌지 않을 때까지):
    - 2a. 각 클러스터의 중심(centroid) 계산(특성 평균 벡터)
    - 2b. 각 관측치를 가장 가까운 중심의 클러스터에 재할당(거리 예=유클리드)
- K-means 알고리즘 특성
  - 위 반복은 매 단계 목표함수 값을 감소시킴(군집 내 평균 제곱거리의 성질 때문)
  - 단, 전역(global) 최솟값 보장은 아님 → 초기값에 따라 지역 최솟값으로 수렴 가능

#### K-means 알고리즘 단계별 진행
- ![K-means 1](수업자료4/3-2%20K-means%20알고리즘1.png)
- ![K-means 2](수업자료4/3-2%20K-means%20알고리즘2.png)

#### K-means 클러스터링에서 초기값의 영향
- 다른 초기값의 영향
  - 서로 다른 초기 레이블에서 최종 분할과 목표값(패널 상단 숫자)이 달라짐
  - 초기화의 중요성: 여러 번 시도 권장
- ![초기값의 영향](수업자료4/3-3%20초기값의%20영향.png)

### 계층적 군집(Hierarchical Clustering)
#### 계층적 군집(Hierarchical Clustering)
- K-means 클러스터링 vs 계층적 군집(Hierarchical Clustering)
  - K-means는 클러스터 수 K를 미리 지정해야 하는 단점이 존재함
  - 계층적 군집은 K를 고정하지 않고 전체 구조를 덴드로그램으로 제공
  - 이번엔 상향식(agglomerative)을 다룸: 잎→몸통으로 병합
- 계층적 군집 결과 예시
  - 덴드로그램에서 수평선 높이(거리)를 기준으로 가위질하여 K개 군집을 얻음
- ![덴드로그램](수업자료4/4-1%20덴드로그램.png)

#### 계층적 군집 알고리즘(상향식)
![계층적 군집 알고리즘1](수업자료4/4-2%20계층적%20군집%20알고리즘1.png)
![계층적 군집 알고리즘2](수업자료4/4-2%20계층적%20군집%20알고리즘2.png)

#### 계층적 군집 단계별 진행
- 계층적 군집 병합 진행 예
  - 데이터들이 점차 큰 클러스터로 합쳐지는 과정
  - 매 단계에서 클러스터들끼리의 병합이 이루어짐
  - 1개의 단일 클러스터가 될 때까지 진행
- 계층적 군집의 계산량:
  - 매 단계에서 모든 클러스터 쌍 간의 거리를 계산해야 함.
  - 데이터의 수가 많은 경우 K-means에 비하여 계산량이 많음
- ![계층적 군집 병합 진행 예](수업자료4/4-3%20계층적%20군집%20병합%20진행%20예.png)

#### 계층적 군집의 링크 유형
- 링크(link)의 유형
  - Single(최소 거리) 링크: 두개 클러스터 내 데이터 쌍별 거리 중 최소값을 군집 간 거리로
  - Complete(최대 거리) 링크: 두개 클러스터 내 데이터 쌍별 거리 중 최대값을 군집 간 거리로
  - Average(평균 거리) 링크: 두개 클러스터 내 데이터 쌍별 거리의 평균을 군집 간 거리로
-![링크의 유형](수업자료4/4-4%20링크의%20유형.png)

#### 링크 유형에 따른 계층적 군집 결과
- 링크에 따라 결과가 달라진다
  - 같은 데이터라도 링크 선택에 따라 클러스터링 결과(덴드로그램)가 달라질 수 있음
  - 하나의 링크만 시도하는 것이 아니라 다른 종류의 링크도 사용 권장
- ![링크에 따른 덴드로그램 변화](수업자료4/4-5%20링크에%20따른%20덴드로그램%20변화.png)

### 클러스터링시 주의점
- 클러스터링 체크리스트
  - 스케일링: 표준화(평균 0, 표준편차 1로 입력 변수 변환)가 필요한가?
    - → Yes, 변수 단위 차이 영향 큼.
  - 몇 개의 클러스터가 적합한지?
    - → K-means·계층적 모두 어려운 문제, 합의된 정답 없음
  - 단일 시도가 아닌 여러 번 시도 권장됨

### 요약 및 정리
- 비지도 학습
  - 레이블(정답)이 없는 데이터를 통해 데이터의 구조·패턴·집단을 학습하는 방법
  - 데이터 탐색, 군집 분석, 시각화, 차원 축소, 이상치 탐지 등
- 클러스터링(Clustering)
  - K-평균(K-means): K(클러스터 수)를 미리 정해 분할
  - 계층적 군집(Hierarchical): K를 사전에 고정하지 않음
- 링크(link) 유형
  - Single(최소 거리) 링크: 데이터 쌍별 거리 중 최소값을 군집 간 거리
  - Complete(최대 거리) 링크: 데이터 쌍별 거리 중 최대값을 군집 간 거리
  - Average(평균 거리) 링크: 데이터 쌍별 거리의 평균을 군집 간 거리